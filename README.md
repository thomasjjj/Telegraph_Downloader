# Telegraph / Telegram ImageÂ Scraper ğŸ“¸

Asynchronously download every image referenced in [Telegraph](https://telegra.ph) / [Graph](https://graph.org) pages and in Telegram posts and channels you can access â€“ with builtâ€‘in deduplication, resumable state and polite rateâ€‘limits.

> **Headsâ€‘upÂ âš ï¸**Â  This project is meant for *personal* archiving/backup.  Scraping other peopleâ€™s content may violate the Telegram & Telegraph Terms ofÂ Service and/or local copyright law.  **Use responsibly.**

---

## âœ¨Â Features

|                                   |                                                                                                                 |
|-----------------------------------|-----------------------------------------------------------------------------------------------------------------|
| **Oneâ€‘liner setup**               | `python telegraph_scraper.py` â€“ the first run interactively asks for APIÂ ID/HASH & saveÂ folder; no flags needed |
| **Multiple link types**           | â€¢ Telegraph \( `https://telegra.ph/slug` )  â€¢ Graph  â€¢ Telegram `t.me/c/â€¦/â€¦` individual posts  â€¢ whole channels |
| **Async & rateâ€‘limited**          | Global semaphores keep calls well below Telegramâ€™s fairâ€‘use window                                              |
| **Never reâ€‘downloads**            | Tiny SQLite DB `processed_links.db` remembers every URL + timestamp                                             |
| **Resilient**                     | Gracefully skips 4xx/5xx HTTP errors, RPC errors **and** private channels youâ€™re not part of                   |
| **Totally offline cache**         | Saves raw `page.html` beside every image so you can inspect later                                               |

---

## ğŸ› ï¸  Requirements

* PythonÂ â‰¥â€¯3.9  (tested on 3.9Â â†’Â 3.12)
* A Telegram APIÂ ID & HASH Â â€”Â <https://my.telegram.org/apps>
* `pip install -r requirements.txt`

### `requirements.txt`
```
telethon>=1.35.0
httpx>=0.27.0
beautifulsoup4>=4.12
lxml>=5.2         # optional but faster HTML parsing
```

---

## ğŸš€Â Installation

```bash
# clone the repo
$ git clone https://github.com/<yourâ€‘handle>/telegraph-scraper.git
$ cd telegraph-scraper

# create & activate a virtualâ€‘env (recommended)
$ python -m venv .venv && source .venv/bin/activate

# install deps
$ pip install -r requirements.txt
```

---

## â–¶ï¸Â Usage

```bash
$ python telegraph_scraper.py
```

You will be prompted for:

| Prompt                                           | Example input                                  |
|--------------------------------------------------|-----------------------------------------------|
| **Save directory**                               | `telegraph_images` (press Enter for default)   |
| **Download entire channel?** `(y/n)`             | `y` to walk the whole message history          |
| **Telegram login**                               | Enter your phone number & the code Telegram sends |
| **Target list**                                  | `@big_channel, https://telegra.ph/abc-123, all` |

After that the scraper prints progress:

```
â†³ Telegraph page: https://telegra.ph/abc-123
â†³ 12 images detected on â€¦ downloadingâ€¦
â†³ Telegram post: https://t.me/c/123456789/42
    â–¸ IMG_20250426_090000.jpg
```

### What does **all** do?

Typing `all` crawls *every* dialog you can see in your Telegram client.  The script automatically skips private channels you donâ€™t belong to, so it wonâ€™t crash when it encounters a `t.me/c/...` link it canâ€™t resolve.

---

## âš™ï¸Â Configuration

Variable | Purpose | Default
---------|---------|---------
`IMG_CONCURRENCY` | Max simultaneous image downloads per page | **10**
`LINK_CONCURRENCY` | Max pages/posts scraped in parallel | **4**

Edit the constants at the top of `telegraph_scraper.py` if you need to back off further (e.g. a very slow VPS).

---

## ğŸ—„ï¸Â Data &Â Cache layout

```
telegraph_images/
â”œâ”€â”€ abc-123/               # Telegraph slug
â”‚Â Â  â”œâ”€â”€ page.html
â”‚Â Â  â”œâ”€â”€ 1.jpg 2.jpg â€¦
â”œâ”€â”€ tg_123456789_42/       # Telegram post cache
â”‚Â Â  â””â”€â”€ IMG_0001.png â€¦
processed_links.db          # tiny sqlite (primaryâ€‘key is URL)
```

Delete `processed_links.db` to force a fresh download next run.

---

## ğŸ›Â Troubleshooting

| Symptom | Fix |
|---------|-----|
| **`ValueError: Could not find the input entity for PeerChannel`** | You tried to crawl a private channel youâ€™re not in.  The current version logs a warning and continues. |
| **HTTPÂ 429 /Â 420** | Lower `IMG_CONCURRENCY` and `LINK_CONCURRENCY`; wait a bit. |
| **`ModuleNotFoundError: lxml`** | Either `pip install lxml` or remove it from `requirements.txt`. |

---

## ğŸ™‹Â FAQ

**Q.Â Why interactive `input()` prompts instead of CLI flags?**  
A. Simpler for casual users; the core functions accept parameters so you can wrap them inÂ `argparse` if you prefer.

**Q.Â Can I run this nonâ€‘interactively?**  
Yes â€“ create a `credentials.json` with your APIÂ ID/HASH|SESSION_NAME ahead of time, and pipe the inputs:
```bash
echo "telegraph_images\ny\n@mychannel" | python telegraph_scraper.py
```

---
